{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df304b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a9b1c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test: (6726, 12) (4068, 12) (2302, 12)\n",
      "Train churn rate: 0.0617\n",
      "Val churn rate  : 0.1084\n",
      "Test churn rate : 0.1486\n"
     ]
    }
   ],
   "source": [
    "# Load data & Time-split\n",
    "df = pd.read_csv(\"../data/processed/account_features_v1.csv\", parse_dates=[\"snapshot_date\"])\n",
    "\n",
    "TRAIN_END = \"2024-03-31\"\n",
    "VAL_END   = \"2024-08-31\"\n",
    "\n",
    "train = df[df[\"snapshot_date\"] <= TRAIN_END].copy()\n",
    "val   = df[(df[\"snapshot_date\"] > TRAIN_END) & (df[\"snapshot_date\"] <= VAL_END)].copy()\n",
    "test  = df[df[\"snapshot_date\"] > VAL_END].copy()\n",
    "\n",
    "TARGET = \"churn_next_30d\"\n",
    "FEATURES = [\n",
    "    \"usage_events_30d\",\n",
    "    \"usage_events_90d\",\n",
    "    \"usage_trend_30d\",\n",
    "    \"usage_per_seat_30d\",\n",
    "    \"tickets_30d\",\n",
    "    \"escalations_90d\",\n",
    "    \"ticket_rate_30d\",\n",
    "    \"recent_upgrade_flag\",\n",
    "    \"recent_downgrade_flag\",\n",
    "    \"seat_change_30d\",\n",
    "    \"tenure_days\",\n",
    "    \"no_active_subscription_flag\",\n",
    "]\n",
    "\n",
    "X_train, y_train = train[FEATURES], train[TARGET]\n",
    "X_val, y_val     = val[FEATURES], val[TARGET]\n",
    "X_test, y_test   = test[FEATURES], test[TARGET]\n",
    "\n",
    "print(\"Train/Val/Test:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Train churn rate:\", round(y_train.mean(), 4))\n",
    "print(\"Val churn rate  :\", round(y_val.mean(), 4))\n",
    "print(\"Test churn rate :\", round(y_test.mean(), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d32700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lightweight Scoring Function\n",
    "def score_probabilistic(pipeline, X, y):\n",
    "    probs = pipeline.predict_proba(X)[:, 1]\n",
    "    return {\n",
    "        \"roc_auc\": roc_auc_score(y, probs),\n",
    "        \"pr_auc\": average_precision_score(y, probs),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c59b58",
   "metadata": {},
   "source": [
    "### Logistic Regression Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5553ce1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR baseline VAL: {'roc_auc': 0.6118, 'pr_auc': 0.1551}\n",
      "LR balanced VAL: {'roc_auc': 0.613, 'pr_auc': 0.1582}\n"
     ]
    }
   ],
   "source": [
    "# Train Baseline LR + Balanced LR\n",
    "pipe_lr_base = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"model\", LogisticRegression(max_iter=2000))\n",
    "])\n",
    "\n",
    "pipe_lr_bal = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "pipe_lr_base.fit(X_train, y_train)\n",
    "pipe_lr_bal.fit(X_train, y_train)\n",
    "\n",
    "lr_base_scores = score_probabilistic(pipe_lr_base, X_val, y_val)\n",
    "lr_bal_scores  = score_probabilistic(pipe_lr_bal, X_val, y_val)\n",
    "\n",
    "print(\"LR baseline VAL:\", {k: round(v, 4) for k, v in lr_base_scores.items()})\n",
    "print(\"LR balanced VAL:\", {k: round(v, 4) for k, v in lr_bal_scores.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3995a8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>C</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lr_bal_C=5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>0.158946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lr_bal_C=10.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.612811</td>\n",
       "      <td>0.158741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr_bal_C=1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.613003</td>\n",
       "      <td>0.158246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lr_bal_C=0.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.614022</td>\n",
       "      <td>0.155232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr_bal_C=0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.618393</td>\n",
       "      <td>0.151486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model_id      C   roc_auc    pr_auc\n",
       "3   lr_bal_C=5.0   5.00  0.612874  0.158946\n",
       "4  lr_bal_C=10.0  10.00  0.612811  0.158741\n",
       "2   lr_bal_C=1.0   1.00  0.613003  0.158246\n",
       "1   lr_bal_C=0.1   0.10  0.614022  0.155232\n",
       "0  lr_bal_C=0.01   0.01  0.618393  0.151486"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune LR Regularization (C Grid)\n",
    "C_GRID = [0.01, 0.1, 1.0, 5.0, 10.0]\n",
    "\n",
    "rows = []\n",
    "models = {}\n",
    "\n",
    "for c in C_GRID:\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", LogisticRegression(max_iter=3000, class_weight=\"balanced\", C=c))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    scores = score_probabilistic(pipe, X_val, y_val)\n",
    "\n",
    "    model_id = f\"lr_bal_C={c}\"\n",
    "    rows.append({\n",
    "        \"model_id\": model_id,\n",
    "        \"C\": c,\n",
    "        \"roc_auc\": scores[\"roc_auc\"],\n",
    "        \"pr_auc\": scores[\"pr_auc\"],\n",
    "    })\n",
    "    models[model_id] = pipe\n",
    "\n",
    "tuning_lr = pd.DataFrame(rows).sort_values(by=[\"pr_auc\", \"roc_auc\"], ascending=False)\n",
    "tuning_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "172f55c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LR artifacts:\n",
      " - ../models/best_lr_pipeline.joblib\n",
      " - ../models/best_lr_model_meta.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_model_id': 'lr_bal_C=5.0',\n",
       " 'best_params': {'C': 5.0, 'class_weight': 'balanced'},\n",
       " 'val_metrics': {'roc_auc': 0.6128744669451275, 'pr_auc': 0.1589462560880725},\n",
       " 'features': ['usage_events_30d',\n",
       "  'usage_events_90d',\n",
       "  'usage_trend_30d',\n",
       "  'usage_per_seat_30d',\n",
       "  'tickets_30d',\n",
       "  'escalations_90d',\n",
       "  'ticket_rate_30d',\n",
       "  'recent_upgrade_flag',\n",
       "  'recent_downgrade_flag',\n",
       "  'seat_change_30d',\n",
       "  'tenure_days',\n",
       "  'no_active_subscription_flag'],\n",
       " 'train_end': '2024-03-31',\n",
       " 'val_end': '2024-08-31',\n",
       " 'model_family': 'logistic_regression'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Best LR Artifact\n",
    "best_lr_row = tuning_lr.iloc[0].to_dict()\n",
    "best_lr_id = best_lr_row[\"model_id\"]\n",
    "\n",
    "best_lr_meta = {\n",
    "    \"best_model_id\": best_lr_id,\n",
    "    \"best_params\": {\"C\": best_lr_row[\"C\"], \"class_weight\": \"balanced\"},\n",
    "    \"val_metrics\": {\"roc_auc\": best_lr_row[\"roc_auc\"], \"pr_auc\": best_lr_row[\"pr_auc\"]},\n",
    "    \"features\": FEATURES,\n",
    "    \"train_end\": TRAIN_END,\n",
    "    \"val_end\": VAL_END,\n",
    "    \"model_family\": \"logistic_regression\",\n",
    "}\n",
    "\n",
    "joblib.dump(models[best_lr_id], \"../models/best_lr_pipeline.joblib\")\n",
    "with open(\"../models/best_lr_model_meta.json\", \"w\") as f:\n",
    "    json.dump(best_lr_meta, f, indent=2)\n",
    "\n",
    "print(\"Saved LR artifacts:\")\n",
    "print(\" - ../models/best_lr_pipeline.joblib\")\n",
    "print(\" - ../models/best_lr_model_meta.json\")\n",
    "best_lr_meta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c1c5f",
   "metadata": {},
   "source": [
    "### Tree Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6ffd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HGB baseline VAL: {'roc_auc': 0.594, 'pr_auc': 0.1369}\n"
     ]
    }
   ],
   "source": [
    "#Train HGB Baseline\n",
    "pipe_hgb_base = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"model\", HistGradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_hgb_base.fit(X_train, y_train)\n",
    "hgb_base_scores = score_probabilistic(pipe_hgb_base, X_val, y_val)\n",
    "\n",
    "print(\"HGB baseline VAL:\", {k: round(v, 4) for k, v in hgb_base_scores.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a74f7bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hgb_1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>0.585692</td>\n",
       "      <td>0.130840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hgb_3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>0.586874</td>\n",
       "      <td>0.129059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hgb_4</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>0.586874</td>\n",
       "      <td>0.129059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hgb_0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0.580337</td>\n",
       "      <td>0.128846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hgb_2</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>0.579587</td>\n",
       "      <td>0.125888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_id  learning_rate  max_depth  max_leaf_nodes   roc_auc    pr_auc\n",
       "1    hgb_1           0.05          5              31  0.585692  0.130840\n",
       "3    hgb_3           0.10          5              31  0.586874  0.129059\n",
       "4    hgb_4           0.10          5              63  0.586874  0.129059\n",
       "0    hgb_0           0.05          3              31  0.580337  0.128846\n",
       "2    hgb_2           0.10          3              31  0.579587  0.125888"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune HGB (Small Grid)\n",
    "grid = [\n",
    "    {\"learning_rate\": 0.05, \"max_depth\": 3, \"max_leaf_nodes\": 31},\n",
    "    {\"learning_rate\": 0.05, \"max_depth\": 5, \"max_leaf_nodes\": 31},\n",
    "    {\"learning_rate\": 0.10, \"max_depth\": 3, \"max_leaf_nodes\": 31},\n",
    "    {\"learning_rate\": 0.10, \"max_depth\": 5, \"max_leaf_nodes\": 31},\n",
    "    {\"learning_rate\": 0.10, \"max_depth\": 5, \"max_leaf_nodes\": 63},\n",
    "]\n",
    "\n",
    "rows = []\n",
    "hgb_models = {}\n",
    "\n",
    "for i, params in enumerate(grid):\n",
    "    pipe = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"model\", HistGradientBoostingClassifier(\n",
    "            random_state=42,\n",
    "            **params\n",
    "        ))\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    scores = score_probabilistic(pipe, X_val, y_val)\n",
    "\n",
    "    model_id = f\"hgb_{i}\"\n",
    "    rows.append({\n",
    "        \"model_id\": model_id,\n",
    "        **params,\n",
    "        \"roc_auc\": scores[\"roc_auc\"],\n",
    "        \"pr_auc\": scores[\"pr_auc\"],\n",
    "    })\n",
    "    hgb_models[model_id] = pipe\n",
    "\n",
    "tuning_hgb = pd.DataFrame(rows).sort_values(by=[\"pr_auc\", \"roc_auc\"], ascending=False)\n",
    "tuning_hgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd06e1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HGB artifacts:\n",
      " - ../models/best_hgb_pipeline.joblib\n",
      " - ../models/best_hgb_model_meta.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_model_id': 'hgb_1',\n",
       " 'best_params': {'learning_rate': 0.05, 'max_depth': 5, 'max_leaf_nodes': 31},\n",
       " 'val_metrics': {'roc_auc': 0.5856923414527101, 'pr_auc': 0.13083983773041796},\n",
       " 'features': ['usage_events_30d',\n",
       "  'usage_events_90d',\n",
       "  'usage_trend_30d',\n",
       "  'usage_per_seat_30d',\n",
       "  'tickets_30d',\n",
       "  'escalations_90d',\n",
       "  'ticket_rate_30d',\n",
       "  'recent_upgrade_flag',\n",
       "  'recent_downgrade_flag',\n",
       "  'seat_change_30d',\n",
       "  'tenure_days',\n",
       "  'no_active_subscription_flag'],\n",
       " 'train_end': '2024-03-31',\n",
       " 'val_end': '2024-08-31',\n",
       " 'model_family': 'hist_gradient_boosting'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune HGB (Small Grid)\n",
    "best_hgb_row = tuning_hgb.iloc[0].to_dict()\n",
    "best_hgb_id = best_hgb_row[\"model_id\"]\n",
    "\n",
    "best_hgb_meta = {\n",
    "    \"best_model_id\": best_hgb_id,\n",
    "    \"best_params\": {\n",
    "        \"learning_rate\": best_hgb_row[\"learning_rate\"],\n",
    "        \"max_depth\": best_hgb_row[\"max_depth\"],\n",
    "        \"max_leaf_nodes\": best_hgb_row[\"max_leaf_nodes\"],\n",
    "    },\n",
    "    \"val_metrics\": {\"roc_auc\": best_hgb_row[\"roc_auc\"], \"pr_auc\": best_hgb_row[\"pr_auc\"]},\n",
    "    \"features\": FEATURES,\n",
    "    \"train_end\": TRAIN_END,\n",
    "    \"val_end\": VAL_END,\n",
    "    \"model_family\": \"hist_gradient_boosting\",\n",
    "}\n",
    "\n",
    "joblib.dump(hgb_models[best_hgb_id], \"../models/best_hgb_pipeline.joblib\")\n",
    "with open(\"../models/best_hgb_model_meta.json\", \"w\") as f:\n",
    "    json.dump(best_hgb_meta, f, indent=2)\n",
    "\n",
    "print(\"Saved HGB artifacts:\")\n",
    "print(\" - ../models/best_hgb_pipeline.joblib\")\n",
    "print(\" - ../models/best_hgb_model_meta.json\")\n",
    "best_hgb_meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a4e416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR_best(5.0)</td>\n",
       "      <td>0.612874</td>\n",
       "      <td>0.158946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR_balanced</td>\n",
       "      <td>0.613003</td>\n",
       "      <td>0.158246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR_baseline</td>\n",
       "      <td>0.611768</td>\n",
       "      <td>0.155106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HGB_baseline</td>\n",
       "      <td>0.593999</td>\n",
       "      <td>0.136865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HGB_best({'learning_rate': 0.05, 'max_depth': ...</td>\n",
       "      <td>0.585692</td>\n",
       "      <td>0.130840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model   roc_auc    pr_auc\n",
       "2                                       LR_best(5.0)  0.612874  0.158946\n",
       "1                                        LR_balanced  0.613003  0.158246\n",
       "0                                        LR_baseline  0.611768  0.155106\n",
       "3                                       HGB_baseline  0.593999  0.136865\n",
       "4  HGB_best({'learning_rate': 0.05, 'max_depth': ...  0.585692  0.130840"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tune HGB (Small Grid)\n",
    "summary = pd.DataFrame([\n",
    "    {\"model\": \"LR_baseline\", **lr_base_scores},\n",
    "    {\"model\": \"LR_balanced\", **lr_bal_scores},\n",
    "    {\"model\": f\"LR_best({best_lr_row['C']})\", \"roc_auc\": best_lr_row[\"roc_auc\"], \"pr_auc\": best_lr_row[\"pr_auc\"]},\n",
    "    {\"model\": \"HGB_baseline\", **hgb_base_scores},\n",
    "    {\"model\": f\"HGB_best({best_hgb_meta['best_params']})\", \"roc_auc\": best_hgb_row[\"roc_auc\"], \"pr_auc\": best_hgb_row[\"pr_auc\"]},\n",
    "])\n",
    "\n",
    "summary = summary[[\"model\", \"roc_auc\", \"pr_auc\"]].sort_values(by=\"pr_auc\", ascending=False)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
